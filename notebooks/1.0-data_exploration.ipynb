{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac0287a",
   "metadata": {},
   "source": [
    "# Data Exploration for Harmonia - Emotional Music Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA) to understand the relationship between musical features and emotional dimensions using the Circumplex Model (Valence-Arousal).\n",
    "\n",
    "## Objectives:\n",
    "1. Analyze emotional label distributions in our dataset\n",
    "2. Extract and explore musical features using librosa\n",
    "3. Identify correlations between audio features and emotional dimensions\n",
    "4. Visualize the emotional landscape of our music dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1adb06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57d563d",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Initial Inspection\n",
    "\n",
    "Let's start by loading our dataset and examining the basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4644f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "DATA_DIR = Path('../data')\n",
    "RAW_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DIR = DATA_DIR / 'processed'\n",
    "DATASET_DIR = Path('../dataset')\n",
    "\n",
    "# Check if dataset directories exist\n",
    "print(f\"Raw data directory exists: {RAW_DIR.exists()}\")\n",
    "print(f\"Processed data directory exists: {PROCESSED_DIR.exists()}\")\n",
    "print(f\"Dataset directory exists: {DATASET_DIR.exists()}\")\n",
    "\n",
    "# List available datasets\n",
    "if DATASET_DIR.exists():\n",
    "    print(\"\\nAvailable datasets:\")\n",
    "    for item in DATASET_DIR.iterdir():\n",
    "        if item.is_dir():\n",
    "            print(f\"- {item.name}\")\n",
    "            for subitem in item.iterdir():\n",
    "                print(f\"  └── {subitem.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc9f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load DEAM dataset annotations\n",
    "def load_deam_annotations(dataset_path):\n",
    "    \"\"\"\n",
    "    Load DEAM dataset annotations from the extracted files\n",
    "    \"\"\"\n",
    "    deam_path = dataset_path / 'DEAM'\n",
    "    \n",
    "    # Check if DEAM annotations exist\n",
    "    annotations_files = list(deam_path.glob('*annotations*'))\n",
    "    if annotations_files:\n",
    "        print(f\"Found annotation files: {[f.name for f in annotations_files]}\")\n",
    "        # TODO: Implement actual loading based on file structure\n",
    "        return None\n",
    "    else:\n",
    "        print(\"No annotation files found. Please extract the DEAM_Annotations.zip file.\")\n",
    "        return None\n",
    "\n",
    "# Attempt to load dataset\n",
    "annotations_df = load_deam_annotations(DATASET_DIR)\n",
    "\n",
    "# For demonstration, create a sample dataset structure\n",
    "# This will be replaced with actual data loading once datasets are extracted\n",
    "print(\"\\nCreating sample data structure for demonstration...\")\n",
    "sample_data = {\n",
    "    'song_id': [f'song_{i:03d}' for i in range(100)],\n",
    "    'valence': np.random.normal(0, 0.3, 100),  # Centered around neutral\n",
    "    'arousal': np.random.normal(0, 0.4, 100),  # Slightly more varied\n",
    "    'file_path': [f'../dataset/DEAM/audio/song_{i:03d}.mp3' for i in range(100)]\n",
    "}\n",
    "\n",
    "# Clip values to realistic range [-1, 1]\n",
    "sample_data['valence'] = np.clip(sample_data['valence'], -1, 1)\n",
    "sample_data['arousal'] = np.clip(sample_data['arousal'], -1, 1)\n",
    "\n",
    "df = pd.DataFrame(sample_data)\n",
    "print(f\"\\nSample dataset shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1e7e3c",
   "metadata": {},
   "source": [
    "## 2. Emotional Label Distribution Analysis\n",
    "\n",
    "Understanding the distribution of emotional labels in our dataset is crucial for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cdd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for emotional dimensions\n",
    "print(\"Emotional Dimensions - Descriptive Statistics:\")\n",
    "print(df[['valence', 'arousal']].describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df[['valence', 'arousal']].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499ded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize emotional distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Valence histogram\n",
    "axes[0,0].hist(df['valence'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0,0].set_title('Valence Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,0].set_xlabel('Valence (Pleasure)')\n",
    "axes[0,0].set_ylabel('Frequency')\n",
    "axes[0,0].axvline(df['valence'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"valence\"].mean():.3f}')\n",
    "axes[0,0].legend()\n",
    "\n",
    "# Arousal histogram\n",
    "axes[0,1].hist(df['arousal'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
    "axes[0,1].set_title('Arousal Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0,1].set_xlabel('Arousal (Activation)')\n",
    "axes[0,1].set_ylabel('Frequency')\n",
    "axes[0,1].axvline(df['arousal'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"arousal\"].mean():.3f}')\n",
    "axes[0,1].legend()\n",
    "\n",
    "# The Circumplex Model - 2D Emotional Space\n",
    "scatter = axes[1,0].scatter(df['valence'], df['arousal'], alpha=0.6, s=50, c=range(len(df)), cmap='viridis')\n",
    "axes[1,0].set_title('Circumplex Model: Emotional Landscape', fontsize=14, fontweight='bold')\n",
    "axes[1,0].set_xlabel('Valence (Negative ← → Positive)')\n",
    "axes[1,0].set_ylabel('Arousal (Low ← → High)')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "axes[1,0].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "axes[1,0].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "\n",
    "# Add quadrant labels\n",
    "axes[1,0].text(0.5, 0.5, 'High Arousal\\nPositive Valence\\n(Joy, Excitement)', \n",
    "               transform=axes[1,0].transAxes, ha='center', va='center', \n",
    "               bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.3))\n",
    "axes[1,0].text(0.5, -0.1, 'Low Arousal\\nPositive Valence\\n(Serenity, Contentment)', \n",
    "               transform=axes[1,0].transAxes, ha='center', va='center',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))\n",
    "axes[1,0].text(-0.1, 0.5, 'High Arousal\\nNegative Valence\\n(Anger, Fear)', \n",
    "               transform=axes[1,0].transAxes, ha='center', va='center',\n",
    "               bbox=dict(boxstyle='round', facecolor='red', alpha=0.3))\n",
    "axes[1,0].text(-0.1, -0.1, 'Low Arousal\\nNegative Valence\\n(Sadness, Depression)', \n",
    "               transform=axes[1,0].transAxes, ha='center', va='center',\n",
    "               bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.3))\n",
    "\n",
    "# Correlation between Valence and Arousal\n",
    "correlation = df['valence'].corr(df['arousal'])\n",
    "axes[1,1].scatter(df['valence'], df['arousal'], alpha=0.6)\n",
    "axes[1,1].set_title(f'Valence vs Arousal Correlation\\n(r = {correlation:.3f})', fontsize=14, fontweight='bold')\n",
    "axes[1,1].set_xlabel('Valence')\n",
    "axes[1,1].set_ylabel('Arousal')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Add trend line\n",
    "z = np.polyfit(df['valence'], df['arousal'], 1)\n",
    "p = np.poly1d(z)\n",
    "axes[1,1].plot(df['valence'], p(df['valence']), \"r--\", alpha=0.8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d61c60",
   "metadata": {},
   "source": [
    "## 3. Audio Feature Extraction Framework\n",
    "\n",
    "Now we'll set up the framework for extracting musical features using librosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9752c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_audio_features(file_path, sr=22050, duration=30):\n",
    "    \"\"\"\n",
    "    Extract comprehensive audio features from a music file\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: path to audio file\n",
    "    - sr: sample rate\n",
    "    - duration: duration in seconds to analyze (None for full track)\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary of extracted features\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load audio file\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "        \n",
    "        # Initialize feature dictionary\n",
    "        features = {}\n",
    "        \n",
    "        # 1. Rhythm/Tempo Features\n",
    "        tempo, beats = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        features['tempo'] = tempo\n",
    "        features['beat_density'] = len(beats) / (len(y) / sr)  # beats per second\n",
    "        \n",
    "        # 2. Spectral Features (Timbre/Texture)\n",
    "        # MFCCs (Mel-Frequency Cepstral Coefficients)\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "        for i in range(20):\n",
    "            features[f'mfcc_{i+1}_mean'] = np.mean(mfccs[i])\n",
    "            features[f'mfcc_{i+1}_std'] = np.std(mfccs[i])\n",
    "        \n",
    "        # Spectral centroid (brightness)\n",
    "        spectral_centroids = librosa.feature.spectral_centroid(y=y, sr=sr)[0]\n",
    "        features['spectral_centroid_mean'] = np.mean(spectral_centroids)\n",
    "        features['spectral_centroid_std'] = np.std(spectral_centroids)\n",
    "        \n",
    "        # Spectral bandwidth\n",
    "        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)[0]\n",
    "        features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)\n",
    "        features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)\n",
    "        \n",
    "        # Spectral rolloff\n",
    "        spectral_rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)[0]\n",
    "        features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)\n",
    "        features['spectral_rolloff_std'] = np.std(spectral_rolloff)\n",
    "        \n",
    "        # Zero crossing rate\n",
    "        zcr = librosa.feature.zero_crossing_rate(y)[0]\n",
    "        features['zcr_mean'] = np.mean(zcr)\n",
    "        features['zcr_std'] = np.std(zcr)\n",
    "        \n",
    "        # 3. Pitch/Harmony Features\n",
    "        # Chroma features\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        for i in range(12):\n",
    "            features[f'chroma_{i+1}_mean'] = np.mean(chroma[i])\n",
    "            features[f'chroma_{i+1}_std'] = np.std(chroma[i])\n",
    "        \n",
    "        # Tonnetz (Tonal centroid features)\n",
    "        tonnetz = librosa.feature.tonnetz(y=librosa.effects.harmonic(y), sr=sr)\n",
    "        for i in range(6):\n",
    "            features[f'tonnetz_{i+1}_mean'] = np.mean(tonnetz[i])\n",
    "            features[f'tonnetz_{i+1}_std'] = np.std(tonnetz[i])\n",
    "        \n",
    "        # 4. Energy Features\n",
    "        # RMS Energy\n",
    "        rms = librosa.feature.rms(y=y)[0]\n",
    "        features['rms_mean'] = np.mean(rms)\n",
    "        features['rms_std'] = np.std(rms)\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Demonstrate feature extraction with a synthetic audio signal\n",
    "print(\"Demonstrating feature extraction with synthetic audio...\")\n",
    "\n",
    "# Create a synthetic audio signal for demonstration\n",
    "sr = 22050\n",
    "duration = 5  # 5 seconds\n",
    "t = np.linspace(0, duration, sr * duration)\n",
    "\n",
    "# Create a simple melody with varying frequencies\n",
    "frequencies = [440, 523, 659, 784]  # A4, C5, E5, G5\n",
    "synthetic_audio = np.concatenate([\n",
    "    np.sin(2 * np.pi * freq * t[:sr]) for freq in frequencies\n",
    "])\n",
    "\n",
    "# Add some noise for realism\n",
    "synthetic_audio += 0.1 * np.random.normal(0, 1, len(synthetic_audio))\n",
    "\n",
    "# Normalize\n",
    "synthetic_audio = synthetic_audio / np.max(np.abs(synthetic_audio))\n",
    "\n",
    "print(f\"Created synthetic audio signal: {len(synthetic_audio)} samples, {len(synthetic_audio)/sr:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ccc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the synthetic audio and its features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Time domain plot\n",
    "time_axis = np.linspace(0, len(synthetic_audio)/sr, len(synthetic_audio))\n",
    "axes[0,0].plot(time_axis, synthetic_audio)\n",
    "axes[0,0].set_title('Synthetic Audio Signal (Time Domain)')\n",
    "axes[0,0].set_xlabel('Time (seconds)')\n",
    "axes[0,0].set_ylabel('Amplitude')\n",
    "\n",
    "# Spectrogram\n",
    "D = librosa.stft(synthetic_audio)\n",
    "S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='hz', ax=axes[0,1])\n",
    "axes[0,1].set_title('Spectrogram')\n",
    "axes[0,1].set_ylabel('Frequency (Hz)')\n",
    "\n",
    "# MFCC features\n",
    "mfccs = librosa.feature.mfcc(y=synthetic_audio, sr=sr, n_mfcc=13)\n",
    "librosa.display.specshow(mfccs, sr=sr, x_axis='time', ax=axes[1,0])\n",
    "axes[1,0].set_title('MFCC Features')\n",
    "axes[1,0].set_ylabel('MFCC Coefficients')\n",
    "\n",
    "# Chroma features\n",
    "chroma = librosa.feature.chroma_stft(y=synthetic_audio, sr=sr)\n",
    "librosa.display.specshow(chroma, sr=sr, x_axis='time', y_axis='chroma', ax=axes[1,1])\n",
    "axes[1,1].set_title('Chroma Features')\n",
    "axes[1,1].set_ylabel('Pitch Class')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract features from synthetic audio (simulate file processing)\n",
    "print(\"\\nExtracting features from synthetic audio...\")\n",
    "# We'll simulate this since we don't have an actual file\n",
    "sample_features = {\n",
    "    'tempo': 120.0,\n",
    "    'spectral_centroid_mean': 2000.5,\n",
    "    'mfcc_1_mean': -150.2,\n",
    "    'chroma_1_mean': 0.7,\n",
    "    'rms_mean': 0.15\n",
    "}\n",
    "\n",
    "print(\"Sample extracted features:\")\n",
    "for feature, value in sample_features.items():\n",
    "    print(f\"{feature}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89590776",
   "metadata": {},
   "source": [
    "## 4. Feature-Emotion Correlation Analysis\n",
    "\n",
    "This section will analyze the relationships between extracted audio features and emotional dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d8158e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For demonstration, let's create some synthetic feature data that correlates with emotions\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic audio features for our sample dataset\n",
    "n_samples = len(df)\n",
    "\n",
    "# Generate features with some correlation to valence and arousal\n",
    "audio_features = {\n",
    "    # Tempo often correlates with arousal\n",
    "    'tempo': 100 + 40 * df['arousal'] + np.random.normal(0, 15, n_samples),\n",
    "    \n",
    "    # Spectral centroid (brightness) often correlates with valence\n",
    "    'spectral_centroid_mean': 2000 + 500 * df['valence'] + np.random.normal(0, 200, n_samples),\n",
    "    \n",
    "    # RMS energy often correlates with arousal\n",
    "    'rms_mean': 0.1 + 0.05 * df['arousal'] + np.random.normal(0, 0.02, n_samples),\n",
    "    \n",
    "    # Add some uncorrelated features for comparison\n",
    "    'mfcc_1_mean': np.random.normal(-150, 20, n_samples),\n",
    "    'mfcc_2_mean': np.random.normal(50, 15, n_samples),\n",
    "    \n",
    "    # Zero crossing rate might correlate with arousal (percussive content)\n",
    "    'zcr_mean': 0.05 + 0.02 * df['arousal'] + np.random.normal(0, 0.01, n_samples),\n",
    "    \n",
    "    # Spectral bandwidth\n",
    "    'spectral_bandwidth_mean': 1000 + 200 * df['valence'] + 150 * df['arousal'] + np.random.normal(0, 100, n_samples),\n",
    "}\n",
    "\n",
    "# Add audio features to dataframe\n",
    "for feature, values in audio_features.items():\n",
    "    df[feature] = values\n",
    "\n",
    "print(f\"Extended dataset shape: {df.shape}\")\n",
    "print(\"\\nAudio features added:\")\n",
    "for feature in audio_features.keys():\n",
    "    print(f\"- {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "feature_columns = list(audio_features.keys())\n",
    "emotion_columns = ['valence', 'arousal']\n",
    "all_columns = emotion_columns + feature_columns\n",
    "\n",
    "correlation_matrix = df[all_columns].corr()\n",
    "\n",
    "# Create correlation heatmap\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, \n",
    "            mask=mask,\n",
    "            annot=True, \n",
    "            cmap='RdBu_r', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            fmt='.3f',\n",
    "            cbar_kws={\"shrink\": .8})\n",
    "plt.title('Feature-Emotion Correlation Matrix', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extract correlations with emotions specifically\n",
    "valence_correlations = correlation_matrix['valence'].drop('valence').sort_values(key=abs, ascending=False)\n",
    "arousal_correlations = correlation_matrix['arousal'].drop('arousal').sort_values(key=abs, ascending=False)\n",
    "\n",
    "print(\"\\nStrongest correlations with VALENCE:\")\n",
    "for feature, corr in valence_correlations.head(5).items():\n",
    "    print(f\"{feature}: {corr:.3f}\")\n",
    "\n",
    "print(\"\\nStrongest correlations with AROUSAL:\")\n",
    "for feature, corr in arousal_correlations.head(5).items():\n",
    "    print(f\"{feature}: {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c111b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detailed scatter plots for the most correlated features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Top valence correlations\n",
    "top_valence_features = valence_correlations.head(3)\n",
    "for i, (feature, corr) in enumerate(top_valence_features.items()):\n",
    "    axes[0, i].scatter(df[feature], df['valence'], alpha=0.6, s=50)\n",
    "    axes[0, i].set_xlabel(feature)\n",
    "    axes[0, i].set_ylabel('Valence')\n",
    "    axes[0, i].set_title(f'{feature} vs Valence\\n(r = {corr:.3f})')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[feature], df['valence'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0, i].plot(df[feature], p(df[feature]), \"r--\", alpha=0.8)\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "\n",
    "# Top arousal correlations\n",
    "top_arousal_features = arousal_correlations.head(3)\n",
    "for i, (feature, corr) in enumerate(top_arousal_features.items()):\n",
    "    axes[1, i].scatter(df[feature], df['arousal'], alpha=0.6, s=50, color='orange')\n",
    "    axes[1, i].set_xlabel(feature)\n",
    "    axes[1, i].set_ylabel('Arousal')\n",
    "    axes[1, i].set_title(f'{feature} vs Arousal\\n(r = {corr:.3f})')\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(df[feature], df['arousal'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[1, i].plot(df[feature], p(df[feature]), \"r--\", alpha=0.8)\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df566150",
   "metadata": {},
   "source": [
    "## 5. Key Insights and Hypotheses\n",
    "\n",
    "Based on our exploratory analysis, let's formulate key insights and hypotheses for model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical significance testing for correlations\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "print(\"STATISTICAL SIGNIFICANCE OF CORRELATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\nVALENCE CORRELATIONS:\")\n",
    "for feature in valence_correlations.head(5).index:\n",
    "    corr, p_value = pearsonr(df[feature], df['valence'])\n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "    print(f\"{feature}: r = {corr:.3f}, p = {p_value:.4f} {significance}\")\n",
    "\n",
    "print(\"\\nAROUSAL CORRELATIONS:\")\n",
    "for feature in arousal_correlations.head(5).index:\n",
    "    corr, p_value = pearsonr(df[feature], df['arousal'])\n",
    "    significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "    print(f\"{feature}: r = {corr:.3f}, p = {p_value:.4f} {significance}\")\n",
    "\n",
    "print(\"\\nLegend: *** p<0.001, ** p<0.01, * p<0.05, ns = not significant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaffff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance ranking for model development\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'valence_corr': [correlation_matrix.loc[feature, 'valence'] for feature in feature_columns],\n",
    "    'arousal_corr': [correlation_matrix.loc[feature, 'arousal'] for feature in feature_columns],\n",
    "})\n",
    "\n",
    "# Calculate combined importance score\n",
    "feature_importance['combined_importance'] = (\n",
    "    abs(feature_importance['valence_corr']) + abs(feature_importance['arousal_corr'])\n",
    ")\n",
    "\n",
    "feature_importance = feature_importance.sort_values('combined_importance', ascending=False)\n",
    "\n",
    "print(\"FEATURE IMPORTANCE RANKING FOR MODEL DEVELOPMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Feature':<25} {'Valence':<10} {'Arousal':<10} {'Combined':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for _, row in feature_importance.iterrows():\n",
    "    print(f\"{row['feature']:<25} {row['valence_corr']:>8.3f} {row['arousal_corr']:>9.3f} {row['combined_importance']:>9.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26707aa",
   "metadata": {},
   "source": [
    "## 6. Next Steps and Recommendations\n",
    "\n",
    "Based on this exploratory analysis, here are the key findings and recommendations for the next phases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e89fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary statistics and save processed data\n",
    "summary_stats = {\n",
    "    'dataset_size': len(df),\n",
    "    'valence_range': (df['valence'].min(), df['valence'].max()),\n",
    "    'arousal_range': (df['arousal'].min(), df['arousal'].max()),\n",
    "    'valence_mean': df['valence'].mean(),\n",
    "    'arousal_mean': df['arousal'].mean(),\n",
    "    'valence_arousal_correlation': df['valence'].corr(df['arousal']),\n",
    "    'top_valence_predictors': valence_correlations.head(3).to_dict(),\n",
    "    'top_arousal_predictors': arousal_correlations.head(3).to_dict(),\n",
    "}\n",
    "\n",
    "print(\"DATASET SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Total samples: {summary_stats['dataset_size']}\")\n",
    "print(f\"Valence range: {summary_stats['valence_range'][0]:.3f} to {summary_stats['valence_range'][1]:.3f}\")\n",
    "print(f\"Arousal range: {summary_stats['arousal_range'][0]:.3f} to {summary_stats['arousal_range'][1]:.3f}\")\n",
    "print(f\"Mean valence: {summary_stats['valence_mean']:.3f}\")\n",
    "print(f\"Mean arousal: {summary_stats['arousal_mean']:.3f}\")\n",
    "print(f\"Valence-Arousal correlation: {summary_stats['valence_arousal_correlation']:.3f}\")\n",
    "\n",
    "print(\"\\nKEY RECOMMENDATIONS:\")\n",
    "print(\"1. Focus on tempo, spectral features, and energy for arousal prediction\")\n",
    "print(\"2. Prioritize spectral centroid and bandwidth for valence prediction\")\n",
    "print(\"3. Consider MFCC features for timbral characteristics\")\n",
    "print(\"4. Implement data augmentation to balance emotional quadrants\")\n",
    "print(\"5. Extract features from 30-second segments for consistent analysis\")\n",
    "\n",
    "# Save the processed dataset\n",
    "output_path = '../data/processed/eda_sample_dataset.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nProcessed dataset saved to: {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
  "ridge": {
    "valence": {
      "model": "Ridge(alpha=100.0)",
      "best_params": {
        "alpha": 100.0
      },
      "metrics": {
        "mse": 0.012314869108409296,
        "rmse": 0.11097237993487072,
        "mae": 0.08622280775457516,
        "r2": 0.5726600787361042
      },
      "predictions": "[0.58528579 0.58575094 0.29582234 0.34781796 0.66361528 0.49632862\n 0.22831484 0.54499649 0.44854576 0.31530397 0.5550339  0.58764125\n 0.71026912 0.59126025 0.39591358 0.39784434 0.67301206 0.39912993\n 0.66579069 0.36951028 0.56014613 0.32752482 0.40135082 0.45705832\n 0.53326385 0.48840338 0.40133419 0.57870452 0.38033935 0.3378589\n 0.58349246 0.31852108 0.6015275  0.7002492  0.54856386 0.73132554\n 0.33263344 0.52938198 0.5419969  0.53256987 0.53106158 0.43693827\n 0.68442061 0.51615688 0.53324485 0.53765531 0.70425544 0.48786203\n 0.4650731  0.7778091  0.44145021 0.66086671 0.2890528  0.33097085\n 0.43093465 0.43724706 0.59609762 0.27046467 0.64329414 0.71116478\n 0.36914874 0.20746092 0.43950825 0.66431418 0.26643688 0.59261609\n 0.36850091 0.53969751 0.62709131 0.24715228 0.41273047 0.29750198\n 0.45331068 0.48127609 0.48017633 0.40852773 0.26736282 0.57496176\n 0.41483362 0.37897531 0.38814901 0.79536108 0.35678562 0.37827716\n 0.53281565 0.42870744 0.51132221 0.38518623 0.44116675 0.47669168\n 0.57776517 0.47311858 0.39959649 0.58345144 0.48291587 0.5842022\n 0.55137339 0.43341892 0.4225655  0.36616949 0.62363459 0.2237387\n 0.6500562  0.58819968 0.39233145 0.4374718  0.65402475 0.46501383\n 0.50082222 0.52806609 0.43554248 0.43791933 0.47262371 0.40485879\n 0.43566608 0.59643077 0.45809093 0.24171163 0.29867111 0.34717202\n 0.27220642 0.64063794 0.58552836 0.58460741 0.36600231 0.50456808\n 0.42210972 0.20961159 0.33704128 0.74477601 0.41393951 0.35263752\n 0.37123711 0.48478282 0.57628633 0.35219848 0.21652019 0.70871649\n 0.35991991 0.40750008 0.36741694 0.93937423 0.42525233 0.57050164\n 0.46339984 0.53299056 0.69091745 0.72528512 0.30362153 0.40884632\n 0.35460668 0.49747427 0.82302642 0.32213045 0.39287106 0.44036824\n 0.44911831 0.33765004 0.66230885 0.13273197 0.56316794 0.25110365\n 0.38591367 0.73501927 0.31344541 0.54424441 0.66037179 0.49160763\n 0.64251864 0.49020099 0.37082528 0.34914946 0.76472603 0.59889286\n 0.33330038 0.45005713 0.34954552 0.62294577 0.48436196 0.65678014\n 0.70298122 0.56530214 0.33638973 0.56303476 0.57454629 0.58085224\n 0.33941898 0.55640148 0.39988938 0.30271613 0.63788322 0.33060753\n 0.40882714 0.45745982 0.36111106 0.35062837 0.34855734 0.43979562\n 0.3667903  0.51093354 0.53781088 0.40331079 0.65080672 0.41988194\n 0.31558182 0.47510359 0.46037626 0.32516038 0.59010035 0.66339443\n 0.49614633 0.5634515  0.78109997 0.54318905 0.35930976 0.55912385\n 0.4645815  0.40898893 0.72476523 0.72756731 0.46841246 0.51539405\n 0.38564728 0.4178945  0.46840857 0.41642793 0.51695831 0.43797971\n 0.62470044 0.73850522 0.61963467 0.30527138 0.45845111 0.32498872\n 0.50122577 0.4047489  0.57108124 0.31828129 0.56574053 0.45419645]"
    },
    "arousal": {
      "model": "Ridge(alpha=100.0)",
      "best_params": {
        "alpha": 100.0
      },
      "metrics": {
        "mse": 0.015966782890209495,
        "rmse": 0.1263597360325254,
        "mae": 0.09906170150764897,
        "r2": 0.4391712173758564
      },
      "predictions": "[0.60034005 0.45774061 0.55730368 0.40463347 0.4814988  0.3418167\n 0.3491013  0.55653031 0.42174826 0.25558924 0.4795163  0.58491098\n 0.18763231 0.48982921 0.37811084 0.52439116 0.6941493  0.34382299\n 0.61021228 0.35998631 0.58667407 0.42804308 0.49262222 0.45880592\n 0.57128003 0.50007687 0.45566139 0.70123584 0.34983436 0.39437918\n 0.5561996  0.26512303 0.71580943 0.65481028 0.61759647 0.63530914\n 0.43548447 0.56961823 0.53858923 0.54414383 0.4955713  0.51131569\n 0.73732841 0.61915753 0.49918527 0.62420513 0.6356505  0.50355778\n 0.52849141 0.50580779 0.41375026 0.65201386 0.30909858 0.35407259\n 0.40985205 0.50262497 0.55930426 0.17656921 0.57661423 0.58105111\n 0.40336542 0.27442367 0.36409102 0.59892748 0.39991261 0.54830159\n 0.39237237 0.5147356  0.68742874 0.32112193 0.43390634 0.3950573\n 0.34648822 0.34437496 0.36869396 0.46695065 0.40492718 0.55329782\n 0.42442023 0.27914706 0.28467474 0.55999574 0.29586877 0.52471615\n 0.59939185 0.36981091 0.57419611 0.46198491 0.36947119 0.57119853\n 0.64463349 0.53767404 0.46720781 0.55251695 0.42657226 0.52544173\n 0.65357074 0.28980359 0.3947514  0.40392328 0.64945609 0.33589837\n 0.59352818 0.42687817 0.36895433 0.45562504 0.67743436 0.46622265\n 0.58804928 0.39894275 0.4532129  0.2500932  0.48007822 0.2816365\n 0.34185258 0.53194585 0.51876666 0.32678803 0.26707089 0.36455799\n 0.2461951  0.57458416 0.5881932  0.44070999 0.40529691 0.40703724\n 0.55635971 0.18877541 0.38612259 0.76589992 0.36131759 0.35340103\n 0.36452241 0.52455286 0.53635316 0.5008074  0.14895953 0.60487712\n 0.48062307 0.2208118  0.31433065 0.82026871 0.53072313 0.57117542\n 0.49091419 0.61506727 0.59846973 0.5740725  0.37112786 0.45763876\n 0.32931278 0.55726637 0.77108802 0.31399908 0.28146631 0.43748505\n 0.4550653  0.40117579 0.65944496 0.22960114 0.5252675  0.13176997\n 0.45155577 0.58575657 0.4283896  0.63779436 0.47168562 0.46872495\n 0.62576581 0.53627918 0.28098449 0.26305727 0.56446384 0.68504089\n 0.44800739 0.56500381 0.47154    0.71981599 0.57710205 0.67093979\n 0.46640475 0.47468193 0.36401879 0.53521395 0.55832989 0.501905\n 0.25703798 0.42086535 0.4807622  0.3151047  0.56016956 0.35713439\n 0.52036346 0.42103454 0.38323481 0.38843283 0.39574413 0.43317841\n 0.30751809 0.50655513 0.53395655 0.34680411 0.60831756 0.33791138\n 0.24195145 0.55437201 0.44535823 0.45286016 0.5472504  0.68218435\n 0.24199318 0.46960862 0.823784   0.47817339 0.27554054 0.61351015\n 0.52776412 0.43808413 0.62820698 0.74945046 0.55856626 0.49537799\n 0.26650204 0.42818195 0.50753052 0.46240614 0.48920423 0.29536356\n 0.59288189 0.66618386 0.63440888 0.18281351 0.39561883 0.50836304\n 0.37502514 0.38924336 0.54013873 0.34068947 0.51193564 0.3638774 ]"
    },
    "system_stats": {
      "current_memory_gb": 7.463367462158203,
      "peak_memory_gb": 7.463367462158203,
      "memory_increase_gb": 0.22212600708007812,
      "elapsed_time_minutes": 0.04287925163904826,
      "cpu_percent": 15.2
    }
  },
  "svr": {
    "valence": {
      "model": "SVR(C=1)",
      "best_params": {
        "C": 1,
        "gamma": "scale",
        "kernel": "rbf"
      },
      "metrics": {
        "mse": 0.012584210186847012,
        "rmse": 0.11217936613676782,
        "mae": 0.08908616389905448,
        "r2": 0.5633136379222017
      },
      "predictions": "[0.55216411 0.58768699 0.44118345 0.28664313 0.59568891 0.47414683\n 0.26131821 0.51001734 0.39274976 0.39065003 0.48280968 0.57691775\n 0.48439072 0.51771255 0.41076972 0.44271159 0.74622208 0.41604331\n 0.64219428 0.35382249 0.55154788 0.33051423 0.48643096 0.43541079\n 0.49948251 0.42526813 0.43068762 0.62326117 0.37426732 0.31527859\n 0.53775241 0.46290137 0.49050354 0.67487741 0.49312017 0.56164686\n 0.31459647 0.55023631 0.5199487  0.51284823 0.51869126 0.45209914\n 0.60859323 0.47286505 0.45532684 0.53651658 0.58266949 0.48725969\n 0.49764182 0.72005144 0.41714156 0.59780443 0.27610534 0.38023407\n 0.45586629 0.4351689  0.63280372 0.43939819 0.62908513 0.64067008\n 0.34117325 0.24252634 0.36083315 0.7253611  0.30792359 0.58464485\n 0.3961188  0.61173965 0.66019562 0.26331686 0.3993583  0.39036541\n 0.45655694 0.47375136 0.55773537 0.39971206 0.40258468 0.58689565\n 0.36373048 0.38955997 0.38980065 0.74459561 0.41848241 0.42787226\n 0.48162558 0.43813867 0.48736173 0.39793288 0.46079625 0.41411821\n 0.5760861  0.46120123 0.37213999 0.63598887 0.45929347 0.59569874\n 0.57353607 0.46824538 0.4120447  0.30296928 0.6524513  0.2397837\n 0.62988884 0.57679937 0.43432717 0.43873366 0.62419279 0.48611927\n 0.49489593 0.53849968 0.44265262 0.42643198 0.47225195 0.4516399\n 0.43969246 0.56994275 0.49367947 0.31208692 0.32445648 0.35178195\n 0.28987605 0.61754911 0.56502768 0.50237783 0.30235058 0.4246605\n 0.41406169 0.33496673 0.38894899 0.75713241 0.36529913 0.30988894\n 0.30287803 0.51254389 0.53281354 0.38809738 0.24789136 0.64304218\n 0.46724613 0.36224749 0.355736   0.49416936 0.44922762 0.54355474\n 0.4830783  0.45283873 0.74100745 0.72382124 0.30735586 0.44156089\n 0.40560167 0.59201384 0.60275948 0.32485072 0.33588497 0.37796762\n 0.54446878 0.297093   0.65965267 0.10891535 0.55947783 0.38804258\n 0.44685922 0.74475029 0.33290715 0.51517383 0.58849598 0.50483806\n 0.59574374 0.53090428 0.38360526 0.31149879 0.81233283 0.55831615\n 0.37863272 0.47224222 0.3289023  0.59505848 0.48454512 0.59162268\n 0.65098717 0.57165411 0.28161155 0.53925496 0.55005707 0.52265926\n 0.44328399 0.48803314 0.37734324 0.29450636 0.53873086 0.3044745\n 0.42767528 0.44191361 0.28224347 0.36346633 0.31481462 0.46466895\n 0.44153472 0.49494202 0.52254974 0.37631152 0.6704598  0.45293806\n 0.33115693 0.49837995 0.44638169 0.25915378 0.61020485 0.6121046\n 0.45356614 0.52920057 0.59714923 0.4905179  0.44983728 0.61540684\n 0.4565367  0.42711527 0.67560926 0.76811739 0.45733332 0.56835594\n 0.38484229 0.40687334 0.3834231  0.48775226 0.50081259 0.55110641\n 0.64331352 0.70636549 0.59306666 0.3875682  0.43628716 0.37948582\n 0.48458247 0.31124985 0.56692666 0.25943745 0.60807447 0.38495316]"
    },
    "arousal": {
      "model": "SVR(C=1, gamma='auto')",
      "best_params": {
        "C": 1,
        "gamma": "auto",
        "kernel": "rbf"
      },
      "metrics": {
        "mse": 0.01475411454625347,
        "rmse": 0.12146651615261496,
        "mae": 0.09388374792484042,
        "r2": 0.48176585373711844
      },
      "predictions": "[0.60758168 0.49738687 0.48691789 0.422467   0.47543522 0.40620714\n 0.257957   0.65118027 0.41679915 0.33239797 0.45755381 0.52737807\n 0.35583224 0.50695096 0.45680975 0.54892041 0.73122739 0.32960141\n 0.60971975 0.32415591 0.57827627 0.51766589 0.54761136 0.51985248\n 0.59455187 0.42403788 0.5110075  0.75380854 0.40084531 0.40644826\n 0.53934795 0.33021141 0.46967896 0.67119479 0.48942001 0.58233298\n 0.41603628 0.54198512 0.55114321 0.57564847 0.54637501 0.43897176\n 0.58745409 0.55356323 0.47190355 0.57059744 0.54445169 0.42636703\n 0.53326459 0.47858249 0.41350083 0.67457924 0.29372363 0.37799889\n 0.40148271 0.4946826  0.5859811  0.29543986 0.62180678 0.60936837\n 0.45323051 0.38176405 0.3744718  0.64923542 0.45513118 0.52429435\n 0.44475191 0.53729491 0.71350558 0.35868225 0.47738232 0.42492965\n 0.36389735 0.28180185 0.31823953 0.37582507 0.4461019  0.50462581\n 0.36060863 0.31748303 0.31607399 0.58727111 0.35376783 0.5399515\n 0.45629985 0.38891643 0.5673792  0.48844364 0.44126645 0.55895573\n 0.60070002 0.51425227 0.43842757 0.55866001 0.4369223  0.45064186\n 0.65440901 0.26956195 0.40770002 0.41428696 0.63056894 0.35454395\n 0.6090347  0.4201559  0.40846481 0.43093063 0.66795149 0.53312718\n 0.53388723 0.42653367 0.42611965 0.33878245 0.44972522 0.31838559\n 0.49148672 0.58621134 0.43182617 0.33104544 0.37850693 0.37581394\n 0.31102634 0.55386885 0.59426052 0.51187971 0.42496493 0.37633756\n 0.51802563 0.41881469 0.4036762  0.75593165 0.42591495 0.29565421\n 0.40654286 0.42793578 0.629414   0.51099068 0.23854709 0.58378666\n 0.50040144 0.26027423 0.3951604  0.46355567 0.53284865 0.5697726\n 0.47865038 0.55507879 0.61674551 0.5148664  0.42602579 0.47307537\n 0.36804342 0.59827333 0.59618249 0.25269552 0.26437129 0.37258553\n 0.52993961 0.38477729 0.67168546 0.28203213 0.49564754 0.30211447\n 0.44107033 0.55928643 0.40472908 0.53583804 0.44909594 0.45284936\n 0.58352557 0.57764793 0.29337309 0.20720486 0.59554742 0.68110408\n 0.48532981 0.59274011 0.42340392 0.76544573 0.54481138 0.66816305\n 0.43523797 0.55269781 0.28290433 0.60910053 0.48619899 0.44721038\n 0.3534125  0.46030388 0.46817281 0.30842488 0.54754068 0.36431693\n 0.53503328 0.43129664 0.36412475 0.42552951 0.40609339 0.4950407\n 0.32849637 0.5474966  0.58493676 0.36092992 0.65259824 0.29619258\n 0.33289342 0.52089463 0.3311636  0.38017219 0.52878258 0.70771325\n 0.29545588 0.45561928 0.62013031 0.47442486 0.40934236 0.69805095\n 0.45384292 0.48860963 0.65226458 0.750573   0.50832616 0.53044301\n 0.28876568 0.35520811 0.53133204 0.49855481 0.47813952 0.42026324\n 0.57927459 0.67133849 0.6078398  0.34155046 0.41907324 0.51245234\n 0.39119474 0.38525141 0.52057514 0.33068161 0.52429386 0.32048439]"
    },
    "system_stats": {
      "current_memory_gb": 7.465358734130859,
      "peak_memory_gb": 7.465358734130859,
      "memory_increase_gb": 0.22411727905273438,
      "elapsed_time_minutes": 0.0284239133199056,
      "cpu_percent": 10.8
    }
  },
  "xgboost": {
    "valence": {
      "model": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=50,\n             n_jobs=2, num_parallel_tree=None, ...)",
      "best_params": {
        "colsample_bytree": 0.8,
        "learning_rate": 0.1,
        "max_depth": 3,
        "n_estimators": 50,
        "subsample": 0.8
      },
      "metrics": {
        "mse": 0.010777360550246029,
        "rmse": 0.10381406720789832,
        "mae": 0.08176363552610079,
        "r2": 0.6260133690069195
      },
      "predictions": "[0.5329986  0.54062533 0.32372764 0.3242671  0.5798468  0.44346198\n 0.28003055 0.56318057 0.3523032  0.37367254 0.57414204 0.6385436\n 0.55326205 0.5193228  0.36744422 0.40632105 0.6946081  0.37218112\n 0.6438242  0.38329658 0.5860806  0.30033374 0.46827525 0.4606266\n 0.55066556 0.47380173 0.44377208 0.58226466 0.33436134 0.3483874\n 0.54679114 0.3882105  0.56296617 0.61570555 0.50507337 0.6760942\n 0.32422954 0.6028014  0.5250154  0.5469494  0.53553265 0.4767388\n 0.6462522  0.5232793  0.51268804 0.60085064 0.6218858  0.4766178\n 0.4898474  0.7301776  0.4386104  0.6422904  0.3300283  0.346804\n 0.42919683 0.50298    0.6098314  0.32804227 0.57863814 0.69307756\n 0.37282395 0.27903217 0.43976462 0.7076544  0.30260283 0.6155182\n 0.4288012  0.5238365  0.6601956  0.29272667 0.34894606 0.43094534\n 0.4610593  0.45962    0.4896169  0.36851755 0.29999533 0.5723801\n 0.4597071  0.35511988 0.40766963 0.72233564 0.34081966 0.3246734\n 0.4581345  0.41599965 0.5275317  0.36762804 0.41129723 0.49070457\n 0.5401711  0.51003796 0.45047778 0.6134002  0.5105799  0.50425595\n 0.51104397 0.42496338 0.4847193  0.30942127 0.569112   0.26062518\n 0.5316068  0.5687157  0.42407823 0.4895196  0.64695436 0.4181341\n 0.48418364 0.5077944  0.38987753 0.33138233 0.44986767 0.42750698\n 0.406613   0.56420785 0.48590282 0.29219922 0.36946714 0.33432657\n 0.34607396 0.6661752  0.5644542  0.53822565 0.31461394 0.49290583\n 0.3967462  0.27499175 0.29121175 0.63778955 0.36090252 0.33892366\n 0.3278719  0.48577848 0.55484533 0.35858715 0.27418944 0.65716594\n 0.49716166 0.4294289  0.32112533 0.70712245 0.46669483 0.5909044\n 0.3859206  0.5341043  0.69179136 0.6930161  0.41282055 0.46238014\n 0.43562323 0.54969394 0.70705783 0.34349453 0.34532806 0.39536002\n 0.53124595 0.29648563 0.66498506 0.29687643 0.54634476 0.28822926\n 0.42428938 0.7195224  0.32147118 0.57138276 0.5946925  0.43957394\n 0.625893   0.54598576 0.36376828 0.39777413 0.7446407  0.5432896\n 0.31443185 0.4777754  0.3161527  0.6064423  0.512432   0.6524988\n 0.6211103  0.6098492  0.3158406  0.5362692  0.593663   0.58183956\n 0.30154365 0.52465856 0.37761015 0.29242983 0.62668264 0.34782508\n 0.45098102 0.47582287 0.38639942 0.35655046 0.28254583 0.4634016\n 0.38402775 0.5721267  0.5275996  0.3597434  0.63261706 0.4287001\n 0.30881324 0.4533093  0.4412548  0.31928435 0.5128601  0.63583326\n 0.4428886  0.5126811  0.7013823  0.46548602 0.4027923  0.55591637\n 0.449746   0.4317858  0.5924988  0.7216845  0.548151   0.5568038\n 0.39980325 0.44624144 0.5263629  0.35438642 0.51774126 0.5168827\n 0.6468188  0.66279036 0.57442516 0.27503172 0.438311   0.33677557\n 0.49265283 0.32815152 0.51756924 0.33825323 0.5693336  0.4161365 ]",
      "feature_importance": "[0.00526197 0.00238837 0.00016801 0.         0.00185729 0.\n 0.         0.00586584 0.00526188 0.         0.00440857 0.00426266\n 0.         0.00017968 0.00398671 0.         0.00227769 0.\n 0.         0.01423282 0.01680741 0.         0.00148548 0.00498869\n 0.00623611 0.00291063 0.02303786 0.00134306 0.00390448 0.\n 0.         0.         0.00083391 0.00378741 0.00357697 0.\n 0.         0.00223435 0.00408266 0.         0.         0.\n 0.         0.         0.         0.00261197 0.         0.\n 0.         0.         0.         0.00010749 0.         0.0017095\n 0.         0.         0.         0.         0.         0.00335342\n 0.         0.0012741  0.00032777 0.         0.00102651 0.\n 0.00066116 0.         0.         0.         0.         0.00285766\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.00543878 0.\n 0.         0.         0.00502727 0.         0.         0.\n 0.         0.         0.         0.0060891  0.00145547 0.\n 0.         0.         0.         0.         0.00230489 0.\n 0.         0.         0.         0.         0.         0.00273118\n 0.         0.00555561 0.         0.         0.         0.\n 0.01884655 0.         0.01165994 0.         0.         0.\n 0.         0.         0.         0.00759465 0.01541383 0.\n 0.         0.         0.01449068 0.0023993  0.         0.\n 0.00055991 0.00731303 0.00628277 0.         0.02291416 0.00344132\n 0.         0.0037036  0.         0.         0.00483406 0.\n 0.         0.         0.         0.01211878 0.00785392 0.0198622\n 0.00394431 0.00460489 0.04046348 0.00179321 0.         0.\n 0.         0.00488196 0.00042166 0.         0.00308457 0.00981411\n 0.         0.         0.         0.         0.         0.0037437\n 0.00400013 0.01355983 0.         0.00721328 0.         0.0168176\n 0.         0.00260376 0.00165721 0.00590647 0.         0.00601267\n 0.00317131 0.00880416 0.         0.         0.00393012 0.0057031\n 0.         0.         0.         0.00549404 0.00224189 0.\n 0.         0.         0.         0.         0.00393438 0.00705325\n 0.         0.         0.00288838 0.         0.         0.\n 0.00324972 0.         0.00586708 0.00300388 0.         0.\n 0.01851205 0.         0.00210542 0.         0.00850006 0.\n 0.         0.         0.00366443 0.00260403 0.         0.00081641\n 0.00429648 0.         0.         0.         0.00658628 0.\n 0.         0.         0.05255548 0.         0.00358678 0.00488106\n 0.01309158 0.         0.         0.         0.00167586 0.00258209\n 0.00299832 0.00236695 0.         0.         0.00322107 0.00332672\n 0.01079865 0.00395292 0.         0.         0.         0.\n 0.00213826 0.         0.00410113 0.         0.         0.00520609\n 0.00398508 0.00128138 0.         0.         0.         0.00237335\n 0.0028351  0.         0.         0.         0.0021888  0.\n 0.         0.         0.00282266 0.         0.         0.00298318\n 0.00070261 0.00203557 0.         0.         0.         0.\n 0.         0.         0.00135903 0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.00203474 0.00321599 0.00243446 0.\n 0.         0.         0.         0.         0.003527   0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.         0.         0.         0.\n 0.         0.         0.00397785 0.         0.         0.\n 0.         0.         0.         0.         0.00167046 0.\n 0.         0.         0.00280344 0.         0.         0.\n 0.         0.00334051 0.         0.         0.         0.\n 0.00122365 0.         0.         0.00316327 0.00395081 0.\n 0.         0.00290751 0.00566737 0.00243283 0.         0.\n 0.01042249 0.00093857 0.007645   0.         0.         0.\n 0.         0.0034986  0.         0.         0.         0.\n 0.         0.00196898 0.00378006 0.         0.         0.\n 0.00186873 0.         0.01945025 0.         0.00492516 0.00968343\n 0.         0.         0.         0.         0.03550035 0.\n 0.         0.00330957 0.00122178 0.         0.         0.\n 0.         0.         0.00275238 0.         0.         0.\n 0.         0.         0.00221694 0.00566177 0.00241666 0.\n 0.         0.         0.         0.         0.01440884 0.00382945\n 0.         0.         0.         0.         0.         0.\n 0.01005035 0.         0.00390866 0.         0.         0.\n 0.         0.00277801 0.00485065 0.         0.00230217 0.\n 0.00884681 0.         0.         0.00201189 0.00488297 0.\n 0.         0.         0.00864003 0.00357234 0.00412876 0.\n 0.         0.00302451 0.00262067 0.00504554 0.         0.00347808\n 0.         0.         0.00517546 0.         0.         0.\n 0.         0.00468296 0.00194483 0.         0.0054092  0.00397688\n 0.         0.         0.01816861 0.00354682 0.         0.\n 0.00744033 0.00246447 0.         0.        ]"
    },
    "arousal": {
      "model": "XGBRegressor(base_score=None, booster=None, callbacks=None,\n             colsample_bylevel=None, colsample_bynode=None,\n             colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n             enable_categorical=False, eval_metric=None, feature_types=None,\n             feature_weights=None, gamma=None, grow_policy=None,\n             importance_type=None, interaction_constraints=None,\n             learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n             max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n             max_leaves=None, min_child_weight=None, missing=nan,\n             monotone_constraints=None, multi_strategy=None, n_estimators=100,\n             n_jobs=2, num_parallel_tree=None, ...)",
      "best_params": {
        "colsample_bytree": 0.8,
        "learning_rate": 0.1,
        "max_depth": 3,
        "n_estimators": 100,
        "subsample": 0.8
      },
      "metrics": {
        "mse": 0.01369662501705018,
        "rmse": 0.11703258100653074,
        "mae": 0.0903993510355552,
        "r2": 0.5189098776384217
      },
      "predictions": "[0.5130139  0.470666   0.3403085  0.4337309  0.44382817 0.2923536\n 0.36360314 0.66778815 0.4223064  0.32462853 0.5366379  0.67919594\n 0.48112705 0.5602207  0.36168635 0.465816   0.6420969  0.2673577\n 0.66424143 0.3816338  0.5205898  0.42825547 0.52458483 0.49044445\n 0.5335896  0.52496713 0.537613   0.6782023  0.42711216 0.38855705\n 0.54687476 0.2147679  0.6526283  0.5905607  0.58494323 0.6192089\n 0.36789468 0.5557668  0.58002394 0.51542795 0.54364574 0.45536184\n 0.60462135 0.57360256 0.49257657 0.57673043 0.5686965  0.44888717\n 0.5082612  0.56541926 0.45462722 0.6826902  0.39708787 0.3015094\n 0.37341008 0.4992835  0.61265177 0.22039229 0.6045964  0.6807275\n 0.45145932 0.32499114 0.39310464 0.5618444  0.41481766 0.53042156\n 0.4303668  0.49170893 0.72869664 0.2706681  0.43614563 0.5055624\n 0.34326085 0.27605152 0.3441101  0.40438724 0.42761013 0.62094164\n 0.39659405 0.29458973 0.28634843 0.5997393  0.20848088 0.46700016\n 0.5062966  0.43982142 0.51697135 0.43236324 0.3630427  0.4759562\n 0.5656197  0.48898554 0.423823   0.5635089  0.44969723 0.45170248\n 0.6412438  0.23256005 0.50272703 0.3217788  0.66618335 0.40499824\n 0.5798402  0.36326653 0.44324014 0.42541724 0.6576286  0.32551408\n 0.5549233  0.4147648  0.43328735 0.25184387 0.51866114 0.3685114\n 0.392104   0.5534637  0.54541624 0.35972854 0.33398014 0.35601208\n 0.2581314  0.6207169  0.63804823 0.5054475  0.37591502 0.35203198\n 0.44393912 0.31791025 0.42448077 0.70961666 0.48430353 0.29762885\n 0.3980317  0.50091535 0.6115119  0.52296036 0.27311468 0.6090498\n 0.5891025  0.19759525 0.3279062  0.6423672  0.5964183  0.6621595\n 0.39873347 0.5909033  0.5581431  0.56491244 0.4171656  0.5320508\n 0.30052748 0.563211   0.6852156  0.34142888 0.24764706 0.34947714\n 0.5392073  0.37953597 0.6768849  0.34786385 0.47347066 0.25149006\n 0.31060123 0.6127885  0.409974   0.6268239  0.5011169  0.3664946\n 0.60915285 0.5619535  0.25389314 0.24027699 0.5859613  0.65691787\n 0.4543687  0.6002968  0.44378278 0.72465473 0.5826947  0.69789237\n 0.43098503 0.55997276 0.32154512 0.5585006  0.563101   0.61066496\n 0.31253254 0.474367   0.45343858 0.37958527 0.6316912  0.40103734\n 0.4945205  0.45300823 0.44894943 0.39947405 0.36800686 0.484514\n 0.30498004 0.6107201  0.5400418  0.2380467  0.56868225 0.24580033\n 0.27391618 0.45989197 0.30955532 0.32555637 0.4493695  0.6705515\n 0.3543513  0.4870282  0.70126545 0.33281815 0.2460375  0.67556167\n 0.4699908  0.44636244 0.6286014  0.70502806 0.48928759 0.591439\n 0.26558238 0.32534266 0.61445004 0.48679265 0.5342032  0.46738073\n 0.6640815  0.60972357 0.58528155 0.26064962 0.26679    0.41388792\n 0.41031852 0.3462202  0.4495994  0.34202605 0.49511138 0.2751518 ]",
      "feature_importance": "[8.88744486e-04 2.11539329e-03 9.11082971e-05 0.00000000e+00\n 8.18857225e-04 2.70410511e-03 2.21540290e-03 1.52872433e-03\n 8.14810744e-04 1.14750024e-03 4.31998493e-03 4.93308390e-03\n 1.54535356e-03 0.00000000e+00 2.38991599e-03 3.36407078e-03\n 2.75271712e-03 8.86082929e-03 2.04273523e-03 4.12291940e-03\n 4.92530584e-04 3.38643906e-03 6.81326538e-03 6.75439695e-03\n 5.91943564e-04 4.79690079e-03 3.44220735e-02 1.98602001e-03\n 1.33074791e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 1.19585986e-03 5.25489077e-03 1.09898588e-02 0.00000000e+00\n 0.00000000e+00 9.76031413e-04 0.00000000e+00 3.63500905e-03\n 2.46822694e-03 2.11992720e-03 1.77935848e-03 0.00000000e+00\n 2.12605484e-03 0.00000000e+00 7.00372458e-03 3.53330025e-03\n 0.00000000e+00 9.67978965e-04 0.00000000e+00 0.00000000e+00\n 2.40309630e-03 0.00000000e+00 0.00000000e+00 2.23058066e-03\n 6.30754861e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 2.36954424e-03 0.00000000e+00 9.54084448e-04\n 0.00000000e+00 1.70031679e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.35780289e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.16935412e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 7.38460687e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 1.56687270e-03 0.00000000e+00 0.00000000e+00 7.81626813e-03\n 4.95013548e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 2.46904464e-03 4.41776309e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 9.68169072e-04 1.74888293e-03 1.65099313e-03\n 0.00000000e+00 8.30376870e-04 0.00000000e+00 1.33560167e-03\n 0.00000000e+00 0.00000000e+00 1.18083158e-03 0.00000000e+00\n 1.59298151e-03 6.59897225e-04 1.94627012e-03 1.88531890e-03\n 1.68167485e-03 2.07095081e-03 2.73333117e-03 8.94305669e-03\n 1.09837146e-03 6.14512304e-04 8.56597628e-03 2.16269330e-03\n 9.44077037e-04 0.00000000e+00 3.92577518e-03 2.47228798e-03\n 1.21459027e-03 1.40614889e-03 9.04379413e-04 5.79045899e-03\n 0.00000000e+00 2.73997034e-03 0.00000000e+00 1.35671161e-02\n 0.00000000e+00 0.00000000e+00 5.54707367e-03 2.39072181e-03\n 1.10986619e-03 0.00000000e+00 1.22679747e-03 1.03499310e-03\n 5.76986175e-04 1.44221447e-03 1.40923052e-03 1.25149149e-03\n 7.58707151e-03 1.26971316e-03 5.37893400e-02 8.28723423e-03\n 2.11994513e-04 3.65430187e-03 1.58120901e-03 0.00000000e+00\n 2.35691201e-02 0.00000000e+00 8.64086207e-03 0.00000000e+00\n 0.00000000e+00 3.07688653e-03 1.04703102e-02 1.31829188e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 2.32063909e-03 0.00000000e+00 3.38695920e-03 6.81283558e-03\n 1.74926908e-03 0.00000000e+00 1.44833587e-02 0.00000000e+00\n 1.52927521e-03 3.66677716e-03 0.00000000e+00 1.75109529e-03\n 0.00000000e+00 1.53847015e-03 0.00000000e+00 2.98766792e-03\n 0.00000000e+00 3.24612111e-03 1.61540089e-03 2.16174801e-03\n 0.00000000e+00 1.01013626e-04 1.42811937e-03 6.58067176e-03\n 6.03015651e-04 4.00978699e-03 1.55718706e-03 4.30291891e-03\n 0.00000000e+00 2.24625971e-03 1.48397288e-03 1.12166535e-03\n 2.62061926e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.29962491e-03 0.00000000e+00 3.97525402e-03\n 1.17423735e-03 0.00000000e+00 4.33909940e-03 3.93752661e-03\n 1.17914332e-03 1.31193863e-03 0.00000000e+00 1.42452912e-03\n 0.00000000e+00 2.48592603e-03 1.62373204e-03 1.38595572e-03\n 1.23211544e-03 5.47250442e-04 9.56498261e-04 0.00000000e+00\n 1.65689166e-03 2.46275123e-03 1.69473875e-03 1.59767922e-03\n 1.47080340e-03 4.91974689e-03 0.00000000e+00 0.00000000e+00\n 2.23247963e-03 6.73532893e-04 1.37647556e-03 1.96529273e-03\n 2.42721825e-03 3.09030386e-03 1.54316099e-03 3.62373050e-03\n 5.01085632e-03 4.13856236e-03 1.37190265e-03 2.49098358e-03\n 3.15681496e-03 1.26701326e-03 5.24870644e-04 8.45173548e-04\n 2.41270871e-03 5.37978997e-03 2.66527804e-03 5.16574597e-03\n 2.95855049e-02 0.00000000e+00 9.84679675e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 3.28320777e-03 1.64959708e-03 2.74760881e-03 3.54475644e-03\n 0.00000000e+00 0.00000000e+00 2.22947425e-03 2.77712964e-03\n 1.98556064e-03 0.00000000e+00 1.98373315e-03 1.50860439e-03\n 5.10979118e-03 1.23798009e-03 0.00000000e+00 0.00000000e+00\n 1.16601884e-02 0.00000000e+00 0.00000000e+00 2.06297054e-03\n 0.00000000e+00 0.00000000e+00 1.18214230e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 1.70849776e-03 2.26549082e-03\n 6.89870445e-03 0.00000000e+00 0.00000000e+00 2.20041303e-03\n 8.00504442e-03 7.65858043e-04 1.67541543e-03 0.00000000e+00\n 3.03472974e-03 0.00000000e+00 1.55095931e-03 0.00000000e+00\n 9.76652023e-04 0.00000000e+00 1.18504104e-03 8.23201786e-04\n 0.00000000e+00 0.00000000e+00 7.92842067e-04 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 5.54191228e-03 0.00000000e+00 6.19947154e-04 0.00000000e+00\n 2.70827976e-03 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 1.89923437e-03 1.45082758e-03 1.57991599e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.86265747e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.69166771e-03 0.00000000e+00 2.73218774e-03\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 7.11265905e-03\n 4.69761528e-03 2.18909723e-03 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.46963482e-03 1.95555482e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 3.36675509e-03 3.60382418e-03\n 3.31719662e-03 0.00000000e+00 0.00000000e+00 1.39330828e-03\n 1.72654647e-04 2.24583363e-03 1.34578010e-03 5.63014764e-03\n 1.52683759e-03 0.00000000e+00 2.45049829e-03 7.50252279e-04\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.34133168e-03\n 1.38055743e-03 2.05637375e-03 1.16536778e-03 9.69159976e-03\n 3.63495434e-03 0.00000000e+00 0.00000000e+00 6.31318334e-03\n 2.82449927e-03 1.13513018e-03 7.44436635e-04 1.42924406e-03\n 2.19126092e-03 0.00000000e+00 9.96805262e-04 2.45673326e-03\n 0.00000000e+00 0.00000000e+00 1.46219763e-03 0.00000000e+00\n 0.00000000e+00 4.43873927e-04 3.58549110e-03 1.63369125e-03\n 1.28169637e-02 1.40782632e-03 3.74475890e-03 0.00000000e+00\n 1.56069431e-03 0.00000000e+00 1.18729740e-03 1.14081160e-03\n 3.41282077e-02 1.23831385e-03 2.05723080e-03 2.59305676e-03\n 3.38575640e-03 0.00000000e+00 1.22497603e-03 6.01115217e-03\n 0.00000000e+00 0.00000000e+00 1.81417668e-03 3.07008252e-03\n 8.71334039e-03 0.00000000e+00 7.68161961e-04 1.19157252e-03\n 5.58293832e-04 0.00000000e+00 1.29286491e-03 0.00000000e+00\n 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n 0.00000000e+00 1.86454551e-03 1.21555454e-03 2.50493246e-03\n 1.56672893e-03 1.54577615e-03 2.99009169e-03 2.53669592e-03\n 1.98173849e-03 2.23414181e-03 1.93904189e-03 3.05340858e-03\n 0.00000000e+00 0.00000000e+00 1.09719939e-03 5.16838022e-03\n 9.49006411e-04 0.00000000e+00 3.12260818e-03 0.00000000e+00\n 1.01222564e-02 1.92548335e-03 2.09862576e-03 2.87075108e-03\n 0.00000000e+00 0.00000000e+00 1.16791937e-03 1.77074713e-03\n 0.00000000e+00 2.03253422e-03 1.31367554e-03 0.00000000e+00\n 4.77005233e-04 1.80805579e-03 7.10409891e-04 2.71493476e-03\n 0.00000000e+00 1.10706640e-03 2.18855543e-03 0.00000000e+00\n 2.29350347e-02 2.65015848e-03 1.09561812e-03 7.83459574e-04\n 8.01580213e-03 2.61964952e-03 1.17459055e-03 0.00000000e+00\n 4.20239754e-03 4.00629034e-03 0.00000000e+00 1.67523860e-03\n 9.34237707e-03 2.39398843e-03 1.82032469e-03 1.14825065e-03\n 5.21867024e-03 3.36960307e-03 0.00000000e+00 0.00000000e+00]"
    },
    "system_stats": {
      "current_memory_gb": 7.497100830078125,
      "peak_memory_gb": 7.497100830078125,
      "memory_increase_gb": 0.255859375,
      "elapsed_time_minutes": 2.2058171232541404,
      "cpu_percent": 6.3
    }
  },
  "mlp": {
    "valence": {
      "model": "MLPRegressor(alpha=0.1, early_stopping=True, hidden_layer_sizes=(64,),\n             learning_rate_init=0.01, random_state=42)",
      "best_params": {
        "alpha": 0.1,
        "hidden_layer_sizes": [
          64
        ],
        "learning_rate_init": 0.01,
        "max_iter": 200
      },
      "metrics": {
        "mse": 0.03189877362658422,
        "rmse": 0.1786022777754646,
        "mae": 0.13900658106037403,
        "r2": -0.10692361323523003
      },
      "predictions": "[ 0.51749128  0.58259945  0.13885452  0.55277999  0.72092083  0.48552192\n  0.25614697  0.50039887  0.48556109  0.33653423  0.74313969  0.65853095\n  0.7142433   0.63569186  0.71732732  0.58488847  0.8876546   0.46209244\n  0.72756293  0.37352132  0.45545778  0.3397174   0.4169681   0.52990336\n  0.58558681  0.28414201  0.30963847  0.61712548  0.20271376  0.48969955\n  0.50682094  0.45471674  0.17080937  0.67594083  0.44036524  0.21188526\n  0.32439914  0.55501493  0.54039469  0.55051668  0.45172366  0.26975877\n  0.42749344  0.57033583  0.23007633  0.44735852  0.73064369  0.40073734\n  0.34461968  0.5844721   0.36669536  0.85135245  0.15910112  0.3813834\n  0.48649791  0.4018063   0.69587687  0.38447654  0.50034395  0.60080101\n  0.23859373  0.02551603  0.34542774  0.77825011  0.1925142   0.45935922\n  0.39801176  0.50043009  0.64875746  0.24737225  0.49273779  0.1848571\n  0.30742942  0.47172564  0.40104217  0.48404289  0.41271564  0.70612336\n  0.52873128  0.4511355   0.47541038  0.77470172  0.47756041  0.52423281\n  1.02769022  0.49109941  0.68991959  0.3739764   0.41601293  0.36178605\n  0.62544796  0.44434931  0.28989459  0.71548286  0.43173252  0.66675946\n  0.59415623  0.44984925  0.1065046   0.39179692  0.66445926 -0.01385678\n  0.39407007  0.60693229  0.39251281  0.46567945  0.4513169   0.4688631\n  0.47864655  0.47887203  0.6529284   0.32513954  0.55199613  0.54451801\n  0.59840744  0.52768538  0.6317809   0.18109574  0.35055062  0.47462469\n  0.15036493  0.5348      0.52870947  0.70451266  0.55245474  0.47494468\n  0.51984455  0.36077266  0.38504683  0.9080523   0.30880123  0.26670842\n  0.32435826  0.5060834   0.51696831  0.39780185  0.1487308   0.70761293\n  0.34964343  0.45381447  0.48603192  1.21584943  0.47348224  0.5962344\n  0.60861138  0.80913788  0.76288021  0.91527956  0.1380262   0.3140451\n  0.46502199  0.43636616  0.56931062  0.17476966  0.43665885  0.41640184\n  0.52643888  0.28963559  1.02939107  0.05181243  0.52713648  0.31998517\n  0.30704333  0.93893282  0.31097181  0.56000722  0.8108934   0.53330068\n  0.637033    0.47752076  0.35068123  0.35616573  0.88848253  0.73247667\n  0.31592125  0.49631465  0.48355179  0.46913064  0.49921705  0.67521801\n  0.39879613  0.37217843  0.29615122  0.4060209   0.61117004  0.63207271\n  0.6721307   0.37480952  0.41998086  0.31485187  0.60754906  0.33557175\n  0.34472861  0.65867566  0.33231248  0.37360661  0.55674895  0.9099443\n  0.47995382  0.59409641  0.49057766  0.37170882  0.73345625  0.4555995\n  0.2912756   0.44811039  0.63427919  0.24315794  0.62545091  0.48769448\n  0.43118292  0.70893941  0.82705934  0.49674272  0.68602053  0.503692\n  0.36017385  0.45159222  0.89143464  0.67991918  0.53222437  0.60794659\n  0.37073743  0.41164882  0.40752632  0.37731195  0.49963907  0.48201458\n  0.49939305  0.91192094  0.64458881  0.50920195  0.45840379  0.32810263\n  0.48741968  0.49779187  0.66987365  0.19922125  0.49410066  0.44375276]"
    },
    "arousal": {
      "model": "MLPRegressor(alpha=0.01, early_stopping=True, hidden_layer_sizes=(32,),\n             learning_rate_init=0.01, random_state=42)",
      "best_params": {
        "alpha": 0.01,
        "hidden_layer_sizes": [
          32
        ],
        "learning_rate_init": 0.01,
        "max_iter": 200
      },
      "metrics": {
        "mse": 0.03839372604396138,
        "rmse": 0.19594317044480367,
        "mae": 0.14686187439966386,
        "r2": -0.3485688874020392
      },
      "predictions": "[ 0.80730384  0.59149483  0.43175105  0.57594817  0.23133014  0.3568844\n  0.50315114  0.30466984  0.41254817  0.5284827   0.74851235  0.46361851\n  0.84370854  0.37048518  0.58737544  0.60344165  1.01896983  0.66615498\n  0.61885362  0.35651057  0.41573107  0.409306    0.80599376  0.61235267\n  0.58124008  0.51731587  0.62769292  0.91185483  0.32104468  0.30755032\n  0.56684581  0.16152942  0.69511785  0.58652886  0.7326124   0.72195486\n  0.38685722  0.68530821  0.66807408  0.49600825  0.17953894  0.35401427\n  0.39393004  0.59669145 -0.05046764  0.7213016   0.60106192  0.45870681\n  0.63249035  0.80880882  0.30384592  0.72965259  0.07393126  0.39343314\n  0.31147374  0.46254312  0.56061494  0.22024462  0.36433958  0.52928175\n  0.51398095  0.21251386  0.31174364  0.34465493  0.31773869  0.51959681\n  0.50820698  0.68561106  0.83079323  0.61979558  0.4947131   0.26967834\n  0.34263664  0.27630059  0.37731108  0.29723092  0.36038427  0.77248614\n  0.33786665  0.41860689  0.41264027  0.42750575  0.29502445  0.5233076\n  0.66540726  0.18817754  0.55492037  0.40839218  0.32682738  0.57588823\n  0.53869069  0.58853812  0.6361844   0.89822672  0.4437343   0.67440203\n  0.63152326  0.28592581  0.29021821  0.44130346  0.71656702  0.48796801\n  0.59289447  0.46076037  0.32792917  0.81945905  0.72917339  0.49521722\n  0.32795683  0.312478    0.51046079 -0.00726999  0.51360283  0.25337975\n  0.61895172  0.54499247  0.04327175  0.20807243  0.18442618  0.37193639\n -0.28359516  0.38531998  0.65491079  0.58883063  0.54934976  0.27168225\n  0.57263678  0.3104038   0.61225541  0.71879629  0.40201269  0.40213342\n  0.2671386   0.33751729  0.45441834  0.47371856  0.4123363   0.35226416\n  0.60207243  0.23610126  0.70568909  1.15661022  0.51623749  0.61370276\n  0.08078991  0.66829907  0.53321698  0.33557122  0.57829952  0.41019466\n  0.80452588  0.48753094  0.72954003  0.28511261  0.19944105  0.45764778\n  0.61430589  0.60493141  0.59597515  0.40966487  0.72397587 -0.17835563\n  0.44067639  0.55271568  0.40438175  0.67148488  0.38714931  0.41322599\n  0.60980723  0.66726748  0.12620411  0.22485196  0.52326625  0.74926622\n  0.56848191  0.57558721  0.2936448   0.87975546  0.44575428  0.66603937\n  0.50540076  0.58697938  0.39658372  0.403514    0.71055397  0.52644732\n  0.47018428  0.60557373  0.64240612  0.09551785  0.46555696  0.38904513\n  0.48075218  0.32477637  0.53625693  0.37410409  0.7479676   0.66602936\n  0.09059106  0.4742373   0.6315938   0.36877855  0.88816364  0.28589041\n  0.06134581  0.60267047  0.22976291  0.46324056  0.81085349  0.84086328\n -0.13249047  0.62662647  0.90309642  0.41025151  0.31556412  0.70374284\n  0.50032731  0.30815034  0.51216866  0.67891285  0.78868846  0.58586619\n  0.19333191  0.52320748  0.61716633  0.93820857  0.58391648  0.43715987\n  0.62545556  0.56917211  0.68382555  0.26080854  0.39263557  0.47435969\n  0.25941146  0.59611844  0.61365273  0.07382062  0.53057856  0.32940976]"
    },
    "system_stats": {
      "current_memory_gb": 7.453723907470703,
      "peak_memory_gb": 7.491054534912109,
      "memory_increase_gb": 0.21248245239257812,
      "elapsed_time_minutes": 0.3675566037495931,
      "cpu_percent": 11.6
    }
  }
}